{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3d48bb",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a partir de un data set muy conocido como es MNIST, el cual busca clasificar imágenes de los digitos codificados a mano. Este conjunto cuenta con 70,000 imagenes de 28x28, por lo que cada uno de los ejemplos cuenta con 784 varibles. pertenecientes a una de las 10 clases ( digitos del 0 al 9). Para cargarla podemos usar el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1801aeec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patrones :(70000, 784) -> (70000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "\n",
    "entradas, salidas = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "print(f\"Patrones :{entradas.shape} -> {salidas.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35b9f1",
   "metadata": {},
   "source": [
    "Con esto se pide realizar las siguientes tareas:\n",
    "\n",
    "1. Tras la carga de los datos anteriores, realizar una división entre entranamiento y test con el 80% de los datos para test y cuya semilla sea 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bedc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patrones :(70000, 784) -> (70000,)\n",
      "Entrenamiento: Entradas (56000, 784), Salidas (56000,)\n",
      "Prueba: Entradas (14000, 784), Salidas (14000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar los datos\n",
    "entradas, salidas = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "print(f\"Patrones :{entradas.shape} -> {salidas.shape}\")\n",
    "\n",
    "# Dividir los datos en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(entradas, salidas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir las dimensiones de los conjuntos de entrenamiento y prueba\n",
    "print(f\"Entrenamiento: Entradas {X_train.shape}, Salidas {y_train.shape}\")\n",
    "print(f\"Prueba: Entradas {X_test.shape}, Salidas {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07358b",
   "metadata": {},
   "source": [
    "2. Definir un pipeline que cuente con una técnica de normalización o estandarización, 1 técnica de reducción de la dimensionalidad y una técnica de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b25bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del pipeline: 0.9441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),         # Estandarización\n",
    "    ('pca', PCA(n_components=50)),        # Reducción de dimensionalidad\n",
    "    ('classifier', RandomForestClassifier())  # Clasificación\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el pipeline en el conjunto de prueba\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(f\"Precisión del pipeline: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330a428",
   "metadata": {},
   "source": [
    "3. Realizar el entrenamiento del pipeline un grid search para optimizar el resultado de la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7948f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200, 'pca__n_components': 100}\n",
      "Precisión del Grid Search: 0.9470\n"
     ]
    }
   ],
   "source": [
    "# Cargar y dividir los datos\n",
    "entradas, salidas = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(entradas, salidas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'pca__n_components': [30, 50, 100],\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 30],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Crear y entrenar el Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Evaluar el Grid Search en el conjunto de prueba\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print(f\"Precisión del Grid Search: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83cd1d3",
   "metadata": {},
   "source": [
    "4. Entrenar un pipeline con los valores óptimos del paso anterior y calcular las medidas oportunas de rendimiento y calcular el tiempo que tarda en ejecutarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b56326e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del pipeline optimizado: 0.9471\n",
      "Tiempo de entrenamiento: 127.51 segundos\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1343\n",
      "           1       0.98      0.98      0.98      1600\n",
      "           2       0.93      0.95      0.94      1380\n",
      "           3       0.92      0.94      0.93      1433\n",
      "           4       0.94      0.95      0.95      1295\n",
      "           5       0.95      0.93      0.94      1273\n",
      "           6       0.96      0.97      0.97      1396\n",
      "           7       0.95      0.95      0.95      1503\n",
      "           8       0.95      0.90      0.93      1357\n",
      "           9       0.92      0.91      0.92      1420\n",
      "\n",
      "    accuracy                           0.95     14000\n",
      "   macro avg       0.95      0.95      0.95     14000\n",
      "weighted avg       0.95      0.95      0.95     14000\n",
      "\n",
      "Matriz de confusión:\n",
      "[[1308    0    8    1    0    4   14    3    4    1]\n",
      " [   0 1573   10    4    1    1    2    2    4    3]\n",
      " [   6    3 1310   13   11    2   10    8   14    3]\n",
      " [   1    1   22 1344    2   18    2   13   16   14]\n",
      " [   3    2    8    1 1235    2    5    4    5   30]\n",
      " [  10    0    7   39    7 1181   15    3    7    4]\n",
      " [   6    0    5    0    9   13 1357    0    6    0]\n",
      " [   7    5   11    3   11    1    0 1427    2   36]\n",
      " [   7   11   16   33    8   23    7   10 1227   15]\n",
      " [   8    4    6   24   33    2    0   36   10 1297]]\n"
     ]
    }
   ],
   "source": [
    "# Cargar y dividir los datos\n",
    "entradas, salidas = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(entradas, salidas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el pipeline con los valores óptimos\n",
    "pipeline_optimizado = Pipeline([\n",
    "('scaler', StandardScaler()),\n",
    "('pca', PCA(n_components=100)),\n",
    "('classifier', RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2))\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline y medir el tiempo de ejecución\n",
    "start_time = time.time()\n",
    "pipeline_optimizado.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "tiempo_entrenamiento = end_time - start_time\n",
    "\n",
    "# Evaluar el pipeline en el conjunto de prueba\n",
    "score = pipeline_optimizado.score(X_test, y_test)\n",
    "\n",
    "# Calcular las métricas de rendimiento\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = pipeline_optimizado.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisión del pipeline optimizado: {score:.4f}\")\n",
    "print(f\"Tiempo de entrenamiento: {tiempo_entrenamiento:.2f} segundos\")\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(report)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a7486-398d-45f9-b23e-639dbe1a64dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
